from backend.llm_chat import llm_chat
import streamlit as st
from dotenv import load_dotenv

load_dotenv()

# ConfiguraÃ§Ãµes da pÃ¡gina
st.set_page_config(
    page_title="Chat With PDF",
    page_icon="ðŸ“ƒ",
    layout="wide",
    menu_items={"About": "https://github.com/Gbrlmoraes/chat_with_pdf"},
)

st.header("Bem-vindo ao ChatWithPDF! ðŸ“ƒ ")

# Configurando sidebar
with st.sidebar:

    st.markdown(
        """
    ---
    ## ðŸ“Œ Links Ãšteis
    ### **Conecte-se comigo:**
    - ðŸ”— [LinkedIn](https://www.linkedin.com/in/gabrielmoraesmagalhaes/)
    ---
    ### **Acesse o projeto:**
    - ðŸ’» [RepositÃ³rio do projeto](https://github.com/Gbrlmoraes/chat_with_pdf)
    - ðŸ“„ [PDF utilizado na demo](https://www.pokemon.com/br/pokemon-estampas-ilustradas/regras)
    ---
    """
    )

    st.caption("Feito por [Gabriel Moraes](https://github.com/Gbrlmoraes/)")

# Define variÃ¡veis que receberÃ£o o histÃ³rico de mensagens do chat
if (
    "historico_prompts_usuario" not in st.session_state
    and "historico_respostas_llm" not in st.session_state
    and "historico_chat" not in st.session_state
):
    st.session_state["historico_prompts_usuario"] = []
    st.session_state["historico_respostas_llm"] = []
    st.session_state["historico_chat"] = []

# Mostra as mensagens existentes
for participante, mensagem in st.session_state["historico_chat"]:
    with st.chat_message(participante):
        st.markdown(mensagem)

# InteraÃ§Ã£o usuÃ¡rio-llm
if prompt := st.chat_input("FaÃ§a uma pergunta sobre o documento utilizado  "):

    # Mostra a pergunta do usuÃ¡rio
    with st.chat_message("human"):
        st.markdown(prompt)

    # Gera a resposta utilizando langchain
    try:
        resposta_llm = llm_chat(
            prompt_usuario=prompt, historico_chat=st.session_state["historico_chat"]
        )
    except Exception as e:
        st.error("Ops, parece que vocÃª atingiu o limite de requisiÃ§Ãµes", icon="ðŸ˜…")
        st.stop()

    # resposta_llm = {"answer": f"O usuÃ¡rio disse {prompt}"}

    # Monstra a resposta no chat
    with st.chat_message("ai"):
        st.markdown(resposta_llm["answer"])

    # Guarda as variÃ¡veis da seÃ§Ã£o
    st.session_state["historico_prompts_usuario"].append(prompt)
    st.session_state["historico_respostas_llm"].append(resposta_llm["answer"])

    st.session_state["historico_chat"].append(("human", prompt))
    st.session_state["historico_chat"].append(("ai", resposta_llm["answer"]))
